### âš¡ Order Execution Engine â€” Decentralized Exchange (DEX)

**Live URL:**
ğŸ‘‰ [https://order-engine.netlify.app/](https://order-engine.netlify.app/)

### ğŸ“Œ Project Overview

This project implements a **high-throughput order execution engine** tailored for the **Solana ecosystem**, focusing on:

* Intelligent decentralized exchange (DEX) routing
* Real-time order lifecycle updates via WebSockets
* Scalable & fault-tolerant processing using distributed workers

The engine emulates core components of real trading systems used in modern DEX platforms.

---

### ğŸ¯ Problem Statement

The goal was to build a **robust, scalable, and fault-tolerant execution engine** that can:

* Process a large number of **parallel trading orders**
* **Intelligently route** each order to the best execution venue (Raydium or Meteora)
* Ensure each user receives **instant, live status updates** through a dedicated WebSocket channel
* Maintain transparent, predictable execution state across Redis, Workers, and PostgreSQL

Below is the high-level architecture used to achieve this:

![Architecture](./assets/architecture.png)

---

### âœ… Order Types Supported

This engine implements **three essential trading order types**:

* **Market Orders** â€” Execute immediately at the best available price
* **Limit Orders** â€” Execute only when the target price condition is reached
* **Sniper Orders** â€” Execute instantly when a token becomes available or a liquidity condition is met

The system was incrementally designed:

1. **Market Orders** (base pipeline)
2. **Limit Orders** (Redis buckets + conditional triggers)
3. **Sniper Orders** (liquidity/availability triggers)

Each order type runs on its **own dedicated worker**, ensuring scalability and clean separation of concerns.

---

### ğŸ§ª Implementation Mode â€” Mock Execution

To focus deeply on architecture, reliability, and real-time behavior, the engine uses a **Mock Execution Mode**:

* DEX quotes returned with **realistic delays (2â€“3 seconds)**
* Prices vary randomly by **2â€“5%**
* Execution simulates real settlement with **slippage, routing, and confirmation stages**

This allowed validating:

* Queue behavior
* Worker concurrency
* WebSocket streaming
* Redis caching
* Failover & fallback logic

without requiring on-chain execution.

---

### ğŸ”„ Core Order Execution Flow

1. **Order Submission**
   User submits an order via:
   `POST /api/orders/execute`

2. **Validation & WebSocket Upgrade**
   API validates input â†’ returns `orderId` â†’ upgrades to WebSocket.

3. **DEX Routing**
   System fetches quotes from mock Raydium & Meteora â†’ selects best venue.

4. **Execution Progress (Live Streaming)**
   User receives real-time updates such as:

   * `pending`
   * `routing`
   * `building`
   * `submitted`
   * `confirmed`
   * `failed`

5. **Settlement Simulation**
   Engine simulates the transaction, slippage, final price, and mock `txHash`.


### ğŸ› ï¸ Key Technologies

| Technology               | Purpose                                                                                       |
| ------------------------ | --------------------------------------------------------------------------------------------- |
| **Node.js + TypeScript** | Strong, type-safe backend runtime ensuring reliability and maintainable code.                 |
| **Fastify**              | Ultra-fast web framework with built-in WebSocket support for real-time updates.               |
| **BullMQ + Redis**       | Distributed job queues enabling high-throughput processing, retries, DLQs, and rate-limiting. |
| **PostgreSQL + Prisma**  | Robust transactional database with type-safe ORM for persistent order storage.                |
| **Redis**                | High-speed in-memory cache for active orders, price feeds, and instant matching.              |
| **Pino**                 | Production-grade structured logging with extremely low overhead.                              |

---

### ğŸš€ Key Features

#### ğŸ”¹ 1. Decoupled & Scalable Architecture

The engine is built using a **microservice-like worker model**, each running independently:

* API Server
* Order Execution Worker
* DBSync Worker
* Stream Worker
* Limit Worker
* Sniper Worker

This separation allows **linear scaling** by simply increasing worker replicas.

---

#### ğŸ”¹ 2. Distributed Worker Model (BullMQ)

Each worker focuses on a single responsibility:

* **Order Worker** â†’ Executes all market + triggered orders
* **Limit Worker** â†’ Monitors price buckets & triggers executions
* **Sniper Worker** â†’ Watches liquidity / token availability events
* **Stream Worker** â†’ Fetches & caches Raydium/Meteora quotes
* **DBSync Worker** â†’ Persists order results to PostgreSQL

This ensures reliability, throughput, and resilience.

---

#### ğŸ”¹ 3. âš¡ High-Speed Matching with Redis Buckets (O(1) Execution)

Limit orders are stored in Redis using an **O(1) lookup model**:

```
limit_bucket:{pair}:{price} â†’ Set(orderIds)
limit:{pair}:{orderId}      â†’ OrderDetails
```

When the Stream Worker updates the BEST price, the Limit Worker instantly checks bucket keys and dispatches all matching orders.

This design enables **instant triggering for multiple orders at the same price**, even under heavy load.

---

#### ğŸ”¹ 4. ğŸ§  Best Price Execution + Failover

The engine continuously compares quotes from:

* **Raydium**
* **Meteora**

It calculates `BEST = max(price - fee)` and stores it in Redis as:

```
quotes:{tokenIn}-{tokenOut}:BEST
```

If live price streaming fails, the system automatically:

â¡ï¸ Falls back to cached quotes
â¡ï¸ Or fetches fresh quotes directly from the DEX router

This ensures uninterrupted execution reliability.

---

#### ğŸ”¹ 5. ğŸ”” Real-time Notifications via WebSockets

Each order establishes a **dedicated WebSocket channel**:

```
ws://server/ws/{orderId}
```

The user receives live updates as the order moves through:

* `pending`
* `routing`
* `building`
* `submitted`
* `confirmed`
* `failed`

Powered by BullMQâ€™s **QueueEvents**, ensuring immediate push updates.

---

#### ğŸ”¹ 6. ğŸ’ª Fintech-Grade Reliability & Retry Logic

The system uses:

* **Exponential Backoff**
* **Jitter**
* **Auto-retries (â‰¤3 attempts)**
* **Dead Letter Queue (DLQ)** for failed jobs
* **Stalled job recovery**
* **Job idempotency via jobId = orderId**


## ğŸ—ï¸ System Architecture

The trading engine is designed using a **highly decoupled, distributed microservices-style architecture**, powered by **BullMQ** for resilient task orchestration and **Redis** for ultra-fast in-memory state management.

This architecture enables:

* High throughput
* Fault isolation
* Horizontal scalability
* Real-time feedback loops

![Architecture](./assets/architecture.png)

### ğŸ”¸ Core Components Overview

* **ğŸ§‘â€ğŸ’» Client**
  Initiates orders and maintains a WebSocket connection for real-time execution updates.

* **ğŸ›£ï¸ API Server (Fastify)**
  Acts as the API gateway. Handles WebSocket upgrades, validates orders, stores early state, and dispatches jobs to workers.

* **âš™ï¸ Workers (BullMQ)**
  Individually responsible for routing, executing, syncing, and monitoring orders.

* **ğŸ—„ï¸ PostgreSQL**
  The source of truth for all completed, historical, or audited trades.

* **âš¡ Redis**
  Powers BullMQ queues and stores active order states, cached quotes, buckets, and transient metadata.

---

## ğŸ” 3-Level Deep Dive into Core Components

---

## 1ï¸âƒ£ API Server (Fastify)

The **Fastify server** is the primary entry point of the system.

### ğŸ”§ Key Responsibilities

#### âœ”ï¸ Structured Logging (Pino)

Provides production-grade logs with metadata, timestamps, and worker-context â€” essential for debugging high-throughput systems.

#### âœ”ï¸ DB + Redis Connectivity

* Creates initial order entries in **PostgreSQL (via Prisma)**
* Stores immediate state in **Redis** for fast retrieval
* Dispatches jobs to **BullMQ queues**

#### âœ”ï¸ Order Distribution Logic

Upon receiving `/api/orders/execute`:

1. Validate input
2. Create a preliminary DB record
3. Push job â†’ **order queue**
4. Open WebSocket channel
5. Return `orderId` instantly

#### âœ”ï¸ Real-Time WS Communication

Streams every stage update:

* `pending`
* `routing`
* `building`
* `submitted`
* `confirmed`
* `failed`

---

## 2ï¸âƒ£ Order Worker (BullMQ)

The **heart of the engine** â€” responsible for executing all Market orders and final execution for triggered Limit/Sniper orders.

### ğŸ§  Core Features

#### âœ”ï¸ Job Routing

Uses **orderId as jobId** â†’ ensures **idempotency** and prevents duplicates.

#### âœ”ï¸ Concurrency Control

Ensures only **one worker** processes a given order job at a time.

#### âœ”ï¸ High Resilience

* Retries with **Exponential Backoff + Jitter**
* Max 3 attempts
* Failed jobs â†’ **Dead Letter Queue (DLQ)**

#### âœ”ï¸ Execution Workflow

1. Fetch BEST price
2. Build mock DEX transaction
3. Simulate slippage
4. Mark Redis state
5. Notify DBSync Worker

This worker guarantees correctness and integrity under load.

---

## 3ï¸âƒ£ Stream Worker

The **data backbone** for pricing, event broadcasting, and real-time routing.

### âš¡ Responsibilities

#### âœ”ï¸ Ultra-Fast Quote Polling

Every **500ms**, fetch simulated Raydium + Meteora quotes:

* Caches them in Redis as **HASHES**
* Computes and saves `BEST` price

Redis keys include:

```
quotes:{tokenIn}-{tokenOut}:RAYDIUM
quotes:{tokenIn}-{tokenOut}:METEORA
quotes:{tokenIn}-{tokenOut}:BEST
```

#### âœ”ï¸ Fallback Logic

If API fetch fails â†’ use last known cached quote.

#### âœ”ï¸ QueueEvents Broadcaster

Pushes live updates (from Order Worker) into the WebSocket layer.

---

## 4ï¸âƒ£ DBSync Worker (BullMQ)

Ensures **database integrity** by moving finalized orders from Redis â†’ PostgreSQL.

### ğŸ§¾ Why This Worker Exists

Decoupling DB writes prevents:

* Slow disk I/O blocking real-time execution
* Queue congestion
* Backpressure issues

### ğŸ“Œ Function

* Reads finalized order state from Redis
* Constructs a complete DB object
* Inserts into PostgreSQL (Prisma)

This ensures *high throughput + strong consistency*.

---

## 5ï¸âƒ£ Conditional Workers â€“ Limit & Sniper

These workers handle logic that must run **continuously** or be **event-triggered**.

---

### ğŸ¯ Limit Worker â€” O(1) Price Matching

Uses Redis buckets for instant execution:

#### Redis Structure

```
orderKey  = limit:{pair}:{orderId}
bucketKey = limit_bucket:{pair}:{targetPrice}
```

#### How It Works

* Watches BEST price
* If BEST â‰¥ targetPrice â†’ move all orderIds in bucket â†’ Order Worker queue
* Guarantees **instant trigger under load**

---

### ğŸ¯ Sniper Worker â€” Event-Based Execution

Designed for:

* Token launch snipes
* Liquidity events
* Volume spikes

It triggers an order the moment required conditions are met.


## ğŸ§ª Testing & Quality Assurance

A rigorous testing workflow was implemented to ensure the reliability, correctness, and high-performance behavior of the engine.

---

## âœ… Unit & Integration Testing

Comprehensive tests were written to validate all critical subsystems:

### ğŸ§­ **Routing Logic**

Ensures the engine always selects the optimal DEX (Raydium/Meteora) based on quotes, liquidity, and timestamps.

### ğŸ§± **Queue Behavior**

Verified:

* Correct job distribution
* Concurrency safety
* Retry logic with **Exponential Backoff + Jitter**
* Automatic fallback to the **Dead Letter Queue (DLQ)** for failed jobs

### ğŸ”„ **WebSocket Lifecycle**

Ensures every order stage (`pending â†’ routing â†’ building â†’ submitted â†’ confirmed`) is pushed to the connected client in real-time.

ğŸ“Œ **Unit Tests Screenshot**
![Unit and Integration Testing](./assets/jest.png)

---

## ğŸ§ª Manual Testing

End-to-end scenarios for Market, Limit, and Sniper orders were validated using Postman/Insomnia.

This helped ensure:

* Input validation
* WebSocket status delivery
* Correct queue routing
* Accurate Redis + DB sync behavior

---

## ğŸ”¥ K6 Load Testing (High Throughput)

K6 tests were executed to benchmark throughput, concurrency, latency, and worker stability.

### ğŸ¯ Load Test Target

* **100 orders/min** sustained
* **â‰¤ 10 concurrent executions**

---

## ğŸš€ K6 Load Testing (High Throughput)

*Market, Limit, Sniper & WebSocket channels tested independently.*

### ğŸ“Š Summary Table

| Test Scenario               | Goal                                           |
| --------------------------- | ---------------------------------------------- |
| **Market Order Throughput** | Validate sustained market execution under load |
| **Limit Order Throughput**  | Stress-test O(1) bucket model + trigger logic  |
| **Sniper Order Throughput** | Validate instant execution when triggers fire  |
| **WebSocket Stability**     | Verify 1000+ status message broadcasts         |

---

## ğŸ“ˆ Market Order Load Test

![Market Order Test](./assets/k6-market.png)

---

## ğŸ“ˆ Limit Order Load Test

![Limit Order Test](./assets/k6-limit.png)

---

## âš¡ Sniper Order Load Test

![Sniper Order Test](./assets/k6-sniper.png)

---

## ğŸ”Œ WebSocket Stability Test

![WebSocket Load Test](./assets/k6-ws.png)

---


## ğŸš€ Deployment

The entire system is deployed using **Docker-based microservice separation**, highlighting production standards and real-world engineering practices.

---

## ğŸ³ Multi-Stage Docker Deployment

To ensure small and secure production images:

* **Builder stage** compiles TypeScript â†’ optimized JS
* **Runtime stage** runs only the compiled dist (no dev dependencies)
* Images include:

  * API Server
  * Order Worker
  * Limit Worker
  * Sniper Worker
  * Stream Worker
  * DBSync Worker
  * PostgreSQL
  * Redis

This demonstrates **clean separation of concerns** similar to a distributed microservices environment.

---

## â˜ï¸ EC2 Deployment & Monitoring

All Dockerized components were deployed to an **AWS EC2 instance** using Docker Compose.

### EC2 Setup Provided:

* Hardened environment
* Multi-container orchestration
* Network isolation between services
* External access only for API & WebSocket server
* Persistent volumes for PostgreSQL & Redis

### Ngrok HTTPS Tunnel

* Created a secure HTTPS tunnel to the EC2 backend using Ngrok.
* Exposed the EC2 HTTP server to a public HTTPS URL for easy access.


### ğŸ“œ Logging & Monitoring

Using **Pino structured logging**, enabling:

* Timestamped event tracking
* Worker-by-worker logs
* Failure analysis
* Performance debugging

---

## ğŸŒ Frontend Access

A minimal frontend was created to visualize real-time order updates.

**Live URL:**
ğŸ‘‰ [https://order-engine.netlify.app/](https://order-engine.netlify.app/)

This UI demonstrates:

* WebSocket live stages
* Market/Limit/Sniper order flows
* End-to-end testing in the browser

---

## ğŸ™ Thank You

Thank you for reviewing the **Order Execution Engine**.
